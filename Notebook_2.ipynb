{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook_2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panford/ML4DD/blob/main/Notebook_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkNDzYZyEQ2Y"
      },
      "source": [
        "# Generative Models for Molecule Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbxXuu_oMhRX"
      },
      "source": [
        "**Author**: Kobby Panford-Quainoo (panford.github.io)\n",
        "\n",
        "**Institution:** African Institute for Mathematical Sciences\n",
        "\n",
        "**Workshop:** International E-workshop on Machine Learning for Drug Discovery, India (05/21)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPbswxV-rM0C"
      },
      "source": [
        "In this tutorial, we will look at how to generate molecules from the SMILES dataset using Adversarial Autoencoders (AAEs). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HCDLVxByFhJ",
        "outputId": "9949c3ea-c5c3-4597-bd55-33f09c208545"
      },
      "source": [
        "#@title Install condalab: We need to install condalab in order to install RDKits with Anaconda, Run this cell and wait for kernel to restart before running the next cells\n",
        "!pip install -q condacolab\n",
        "\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "!conda install -q rdkit  #Install RDKits\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:22\n",
            "üîÅ Restarting kernel...\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.74.0               |   py37h6dcda5c_3         342 KB  conda-forge\n",
            "    boost-cpp-1.74.0           |       hc6e9bd1_3        16.3 MB  conda-forge\n",
            "    cairo-1.16.0               |    h6cf1ce9_1008         1.5 MB  conda-forge\n",
            "    conda-4.10.1               |   py37h89c1867_0         3.1 MB  conda-forge\n",
            "    cycler-0.10.0              |             py_2           9 KB  conda-forge\n",
            "    fontconfig-2.13.1          |    hba837de_1005         357 KB  conda-forge\n",
            "    freetype-2.10.4            |       h0708190_1         890 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    h0b5b191_1005         3.6 MB  conda-forge\n",
            "    greenlet-1.1.0             |   py37hcd2ae1e_0          83 KB  conda-forge\n",
            "    importlib-metadata-4.2.0   |   py37h89c1867_0          30 KB  conda-forge\n",
            "    jpeg-9d                    |       h36c2ea0_0         264 KB  conda-forge\n",
            "    kiwisolver-1.3.1           |   py37h2527ec5_1          78 KB  conda-forge\n",
            "    libblas-3.9.0              |       9_openblas          11 KB  conda-forge\n",
            "    libcblas-3.9.0             |       9_openblas          11 KB  conda-forge\n",
            "    libgfortran-ng-9.3.0       |      hff62375_19          22 KB  conda-forge\n",
            "    libgfortran5-9.3.0         |      hff62375_19         2.0 MB  conda-forge\n",
            "    libglib-2.68.2             |       h3e27bee_0         3.1 MB  conda-forge\n",
            "    liblapack-3.9.0            |       9_openblas          11 KB  conda-forge\n",
            "    libopenblas-0.3.15         |pthreads_h8fe5266_1         9.2 MB  conda-forge\n",
            "    libpng-1.6.37              |       h21135ba_2         306 KB  conda-forge\n",
            "    libtiff-4.0.10             |    hc3755c2_1005         602 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h7f98852_1000          28 KB  conda-forge\n",
            "    libxcb-1.13                |    h7f98852_1003         395 KB  conda-forge\n",
            "    matplotlib-base-3.4.2      |   py37hdd32ed1_0         7.2 MB  conda-forge\n",
            "    numpy-1.20.3               |   py37h038b26d_1         5.7 MB  conda-forge\n",
            "    olefile-0.46               |     pyh9f0ad1d_1          32 KB  conda-forge\n",
            "    openssl-1.1.1k             |       h7f98852_0         2.1 MB  conda-forge\n",
            "    pandas-1.2.4               |   py37h219a48f_0        11.8 MB  conda-forge\n",
            "    pcre-8.44                  |       he1b5a44_0         261 KB  conda-forge\n",
            "    pillow-6.2.1               |   py37h6b7be26_0         637 KB  conda-forge\n",
            "    pixman-0.40.0              |       h36c2ea0_0         627 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h36c2ea0_1001           5 KB  conda-forge\n",
            "    pycairo-1.20.0             |   py37hfff247e_1          77 KB  conda-forge\n",
            "    pyparsing-2.4.7            |     pyh9f0ad1d_0          60 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    pytz-2021.1                |     pyhd8ed1ab_0         239 KB  conda-forge\n",
            "    rdkit-2021.03.2            |   py37haf5a968_0        38.3 MB  conda-forge\n",
            "    reportlab-3.5.67           |   py37h69800bb_0         2.4 MB  conda-forge\n",
            "    sqlalchemy-1.4.15          |   py37h5e8e339_0         2.2 MB  conda-forge\n",
            "    tornado-6.1                |   py37h5e8e339_1         646 KB  conda-forge\n",
            "    typing_extensions-3.7.4.3  |             py_0          25 KB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h7f98852_1002          27 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h7f98852_0          58 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    hd9c2040_1000          26 KB  conda-forge\n",
            "    xorg-libx11-1.7.1          |       h7f98852_0         946 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h7f98852_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h7f98852_0          19 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h7f98852_1          54 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h7f98852_1003          32 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h7f98852_1002           9 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h7f98852_1002          28 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h7f98852_1007          73 KB  conda-forge\n",
            "    zipp-3.4.1                 |     pyhd8ed1ab_0          11 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       115.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.74.0-py37h6dcda5c_3\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.74.0-hc6e9bd1_3\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-h6cf1ce9_1008\n",
            "  cycler             conda-forge/noarch::cycler-0.10.0-py_2\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-hba837de_1005\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-h0b5b191_1005\n",
            "  greenlet           conda-forge/linux-64::greenlet-1.1.0-py37hcd2ae1e_0\n",
            "  importlib-metadata conda-forge/linux-64::importlib-metadata-4.2.0-py37h89c1867_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9d-h36c2ea0_0\n",
            "  kiwisolver         conda-forge/linux-64::kiwisolver-1.3.1-py37h2527ec5_1\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-9_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-9_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-9.3.0-hff62375_19\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-9.3.0-hff62375_19\n",
            "  libglib            conda-forge/linux-64::libglib-2.68.2-h3e27bee_0\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-9_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.15-pthreads_h8fe5266_1\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.0.10-hc3755c2_1005\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h7f98852_1003\n",
            "  matplotlib-base    conda-forge/linux-64::matplotlib-base-3.4.2-py37hdd32ed1_0\n",
            "  numpy              conda-forge/linux-64::numpy-1.20.3-py37h038b26d_1\n",
            "  olefile            conda-forge/noarch::olefile-0.46-pyh9f0ad1d_1\n",
            "  pandas             conda-forge/linux-64::pandas-1.2.4-py37h219a48f_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
            "  pillow             conda-forge/linux-64::pillow-6.2.1-py37h6b7be26_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.40.0-h36c2ea0_0\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.20.0-py37hfff247e_1\n",
            "  pyparsing          conda-forge/noarch::pyparsing-2.4.7-pyh9f0ad1d_0\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  pytz               conda-forge/noarch::pytz-2021.1-pyhd8ed1ab_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2021.03.2-py37haf5a968_0\n",
            "  reportlab          conda-forge/linux-64::reportlab-3.5.67-py37h69800bb_0\n",
            "  sqlalchemy         conda-forge/linux-64::sqlalchemy-1.4.15-py37h5e8e339_0\n",
            "  tornado            conda-forge/linux-64::tornado-6.1-py37h5e8e339_1\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-3.7.4.3-py_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h7f98852_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h7f98852_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-hd9c2040_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.7.1-h7f98852_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h7f98852_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h7f98852_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h7f98852_1\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h7f98852_1003\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h7f98852_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h7f98852_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h7f98852_1007\n",
            "  zipp               conda-forge/noarch::zipp-3.4.1-pyhd8ed1ab_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  conda                                4.9.2-py37h89c1867_0 --> 4.10.1-py37h89c1867_0\n",
            "  openssl                                 1.1.1j-h7f98852_0 --> 1.1.1k-h7f98852_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLfRRpxPyJhP"
      },
      "source": [
        "# Imports\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import Model\n",
        "from rdkit.Chem import Descriptors, QED\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.backend import random_normal\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Lambda, Input, RepeatVector, LSTM, LeakyReLU, Dropout\n",
        "from tensorflow.keras.layers import Embedding, Dense, Bidirectional, Concatenate, TimeDistributed\n",
        "\n",
        "tf.random.set_seed(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ffTVdiojDlX"
      },
      "source": [
        "!git clone https://github.com/panford/ML4DD.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzQPjVECyJe-",
        "cellView": "form"
      },
      "source": [
        "#@title Define utility functions for smiles computation here\n",
        "def compute_smile_prop(smile):\n",
        "\n",
        "  \"\"\" \n",
        "  Compute smiles properties (MolWt, LogP, QED)\n",
        "\n",
        "  Inputs:\n",
        "    smile (str, list, tuple) : A sequence or list of sequences of smiles \n",
        "                                data whose properties needs to be computed\n",
        "  Output:\n",
        "    props (list)  :   Computed properties\n",
        "  \n",
        "  \"\"\"\n",
        "\n",
        "  def compute_for_one(smi):\n",
        "\n",
        "    \"\"\"\n",
        "    Computes properties for a single smile sequence\n",
        "\n",
        "    Inputs \n",
        "      smi (str) : A sequence of smile characters\n",
        "    Outputs\n",
        "      prop (list): Computed properties, \"Not exist\" if properties cannot be computed\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        mol=Chem.MolFromSmiles(smi) \n",
        "        prop = [Descriptors.ExactMolWt(mol), Descriptors.MolLogP(mol), QED.qed(mol)]\n",
        "    except:\n",
        "        prop = 'Not exist!'\n",
        "    return prop\n",
        "\n",
        "      \n",
        "  if isinstance(smile, (list, tuple)):\n",
        "    all_list = []\n",
        "    for s in list(smile):\n",
        "      all_list.append(compute_for_one(s))\n",
        "    props = all_list\n",
        "\n",
        "  elif isinstance(smile, str):\n",
        "    props = compute_for_one(smile) \n",
        "  else:\n",
        "    print(f\"Input must be a string or list, Instead got {type(smile)}\")\n",
        "    \n",
        "  return props\n",
        "\n",
        "def canonicalize(smile):\n",
        "  \"\"\"Function to canonicalise smiles inputs sequence\"\"\"\n",
        "\n",
        "  return Chem.MolToSmiles(Chem.MolFromSmiles(smile))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BR-OC1MHsS1",
        "cellView": "form"
      },
      "source": [
        "#@title Utility functions for decoding numerical sequences and generation\n",
        "def greedy_search():\n",
        "  \"\"\"\n",
        "  A decoder algorithm to retrieve sequences from decoder output\n",
        "\n",
        "  Inputs\n",
        "    inputs (tf-tensor): Output from decoder, size (batch, max_seq_len, num_chars)\n",
        "  \n",
        "  Outputs\n",
        "    seq of greedily decoded sequences\n",
        "  \"\"\"\n",
        "  def decode(preds):\n",
        "    return np.argmax(preds).tolist()\n",
        "\n",
        "  return decode\n",
        "\n",
        "\n",
        "\n",
        "def temperature_sampling():\n",
        "  \"\"\"\n",
        "  Temperature sampling wrapper function\n",
        "\n",
        "  This wrapper function will allow us use the temperature sampling strategy to decode our predicted sequences\n",
        "  \"\"\"\n",
        "  def softmax(z):\n",
        "    \"\"\"Softmax function \"\"\"\n",
        "    return np.exp(z)/sum(np.exp(z))\n",
        "\n",
        "  def decode(preds, temperature):\n",
        "\n",
        "    \"\"\" \n",
        "    Decoder using temperature \n",
        "    \"\"\"\n",
        "\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    reweighted_preds = softmax(preds)\n",
        "    probs = np.random.multinomial(1, reweighted_preds, 1)\n",
        "\n",
        "    return np.argmax(probs)\n",
        "\n",
        "  return decode\n",
        "\n",
        "\n",
        "\n",
        "def decode_preds(preds, d_strategy=\"temp\", **decoder_params):\n",
        "\n",
        "  \"\"\"Decoding function: call this with decoder prediction\n",
        "  Inputs\n",
        "    preds (batch_size, max_seq_len, num_chars): softmax prediction from decoder model\n",
        "    d_strategy (str):      Strategy to use for prediction\n",
        "  \"\"\"\n",
        "\n",
        "  \n",
        "  if d_strategy == \"temp\":\n",
        "    strategy = temperature_sampling()\n",
        "    temperature = decoder_params.get('temperature') or 0.5\n",
        "    print('Decoding strategy: ', \"Temperature Sampling (%s) \"%temperature)\n",
        "\n",
        "  elif d_strategy == 'greedy':\n",
        "    strategy = greedy_search()\n",
        "    print('Decoding strategy: ', \"Greedy Search\")\n",
        "  print(\"*\"*8)\n",
        "\n",
        "  seqs = []\n",
        "  for n in range(preds.shape[0]):\n",
        "    batch = []\n",
        "    for l in range(preds.shape[1]):\n",
        "      batch.append(strategy(preds[n,l,:], temperature=temperature))\n",
        "    seqs.append(batch)\n",
        "  decoded_seq = tokenizer.sequences_to_texts(unpad(list(seqs)))\n",
        "  seq = [s.replace(\" \",\"\") for s in decoded_seq]\n",
        "\n",
        "  return seq\n",
        "\n",
        "\n",
        "def generate_smiles_from_prior(model, prior, decoding_strategy = \"temp\", **decoder_params):\n",
        "  \n",
        "  \"\"\"\n",
        "  Generates smiles samples from prior\n",
        "\n",
        "  Inputs\n",
        "    batch_size: Batch size of samples to generate\n",
        "    latent_dim: Latent dimension \n",
        "\n",
        "  outputs\n",
        "    decoded_seq: Decoded sequence\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  predicted_seq = model.predict(prior)\n",
        "\n",
        "  return decode_preds(predicted_seq, decoding_strategy, **decoder_params)\n",
        "\n",
        "\n",
        "def unpad(input_tokens):\n",
        "  \"\"\"Function for unpadding tokens\n",
        "  Inputs\n",
        "    input_tokens  : list of input tokens\n",
        "  Outputs\n",
        "    unpadded tokens (list)\n",
        "  \"\"\"\n",
        "\n",
        "  unpadded = []\n",
        "  for i in range(len(input_tokens)):\n",
        "    unpadded_list = [token for token in input_tokens[i] if token !=0]\n",
        "    unpadded.append(unpadded_list)\n",
        "\n",
        "  return unpadded\n",
        "\n",
        "\n",
        "def generate_random_smiles(model, batch_size, latent_dim, decoding_strategy, **decoder_params):\n",
        "  \n",
        "  \"\"\"\n",
        "  Generates smiles samples from random normal samples\n",
        "\n",
        "  Inputs\n",
        "    batch_size: Batch size of samples to generate\n",
        "    latent_dim: Latent dimension \n",
        "    model     : model to predict from prior\n",
        "\n",
        "  outputs\n",
        "    decoded_seq: Decoded sequence\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  prior = tf.random.normal(shape=[batch_size, latent_dim],)\n",
        "\n",
        "  return generate_smiles_from_prior(model, prior, decoding_strategy, **decoder_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_zbzBk8yJaS"
      },
      "source": [
        "#Lets get the data path\n",
        "path_to_data = \"/content/ML4DD/data/smiles.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtRBx1EwyJX-"
      },
      "source": [
        "# Load up data from path\n",
        "\n",
        "smiles_data = pd.read_csv(path_to_data, header = None)\n",
        "smiles_data = smiles_data[0][:2000] # THis is very huge so select the amount of data you can work with effectively"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXwoIAI0fquW",
        "outputId": "8064c0ac-f746-4eb9-df20-7e52badb373f"
      },
      "source": [
        "compute_smile_prop(smiles_data[:5].tolist()) # Compute properties for the first 5 datapoints"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[217.05063234791, 0.1348999999999997, 0.7060511028948301],\n",
              " [289.07726434, 2.0300999999999996, 0.6535741974690973],\n",
              " [281.08341234000005, 1.6806999999999999, 0.8968983095288725],\n",
              " [281.08341234000005, 1.6806999999999999, 0.8968983095288725],\n",
              " [212.098334132, 1.3038, 0.5630097133159685]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyFGJURO6Qc4",
        "outputId": "202150f8-4e45-49cb-81ed-f7b65a59ecc7"
      },
      "source": [
        "smiles_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            C[C@@]1(C(=O)C=C(O1)C(=O)[O-])c2ccccc2\n",
              "1             c1ccc(cc1)C(c2ccccc2)[S@](=O)CC(=O)NO\n",
              "2    CCC[S@](=O)c1ccc2c(c1)[nH]/c(=N\\C(=O)OC)/[nH]2\n",
              "3    CCC[S@](=O)c1ccc2c(c1)[nH]/c(=N/C(=O)OC)/[nH]2\n",
              "4                  CC(C)C[C@@H]1C(=O)N(C(=S)N1)CC=C\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDlSda4PsJ5w"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Since we are using data represented as SMILES strings, we can use some natual language processing techniques. We'll tokenize the characters which basically means selecting the set of unique characters in the entire dataset. Also in order to make up for the difference in lengths, we'll find the maximum sequence lengths and pad with zeros to the max sequence length. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ojr7liayJVy"
      },
      "source": [
        "# Create a tokenizer to tokenize the characters in the smiles dataset\n",
        "\n",
        "tokenizer = Tokenizer(filters=None,\n",
        "                      lower=False,\n",
        "                      char_level=True)\n",
        "tokenizer.fit_on_texts(smiles_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXo66f3gyJTR",
        "outputId": "351af48f-9794-4464-e4c9-a9a49676aef2"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'c': 1, 'C': 2, '(': 3, ')': 4, '1': 5, 'O': 6, '2': 7, '[': 8, ']': 9, '=': 10, 'N': 11, '3': 12, 'H': 13, '@': 14, 'n': 15, '+': 16, '4': 17, '-': 18, 'l': 19, '/': 20, 'S': 21, 'F': 22, 's': 23, 'o': 24, '#': 25, '\\\\': 26, 'B': 27, 'r': 28, '5': 29, 'I': 30, 'P': 31, '6': 32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOftFqsu-wMI"
      },
      "source": [
        "def create_padded_data(smiles_):\n",
        "\n",
        "  \"\"\"\n",
        "  Creates numerical dataset from character sequences and pads up to the max sequence length\n",
        "  Inputs\n",
        "    smiles_(list):  lists of sequences from data\n",
        "  Outputs:\n",
        "    (nd.array):     An array of padded sequences up to max sequence length\n",
        "    max_seq_len (int): length of longest sequence in the data\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  x_sequences = [] \n",
        "  # Loop through each row\n",
        "  for line in smiles_:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0] #Tokenize each row\n",
        "    x_sequences.append(token_list) # append to x_sequences\n",
        "\n",
        "  # pad sequences \n",
        "  max_seq_len = max([len(x) for x in x_sequences]) # Compute max sequence length\n",
        "\n",
        "  return np.array(pad_sequences(x_sequences, maxlen=max_seq_len, padding='pre')), max_seq_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrM3r-RCx-6Y",
        "outputId": "5846002a-a268-4ad5-f248-09e74bbb8b42"
      },
      "source": [
        "X, max_seq_len = create_padded_data(smiles_data)\n",
        "X[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  2,  8,  2, 14, 14,  9,  5,  3,  2,  3, 10,  6,\n",
              "        4,  2, 10,  2,  3,  6,  5,  4,  2,  3, 10,  6,  4,  8,  6, 18,  9,\n",
              "        4,  1,  7,  1,  1,  1,  1,  1,  7], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVXZ-AUzyJRJ"
      },
      "source": [
        "latent_dim = 10          # Dimension of latent vector \n",
        "batch_size = 100          # Batch size\n",
        "embedding_dim = 100       # Embedding dimension\n",
        "num_chars = len(tokenizer.word_index)+1 # Compute the number of characters or unique tokens\n",
        "                                        # Add one for padding\n",
        "n_units = 96         #Number of GRU units\n",
        "learning_rate = 0.0002    # Learning rate for optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kVbRboU66S0"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(X)  # Create a tensorflow dataset\n",
        "train_dataset = dataset.batch(batch_size).shuffle(1024) # Add batching and shuffling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HkHQgautBBs"
      },
      "source": [
        "[Adversarial autoencoders](https://arxiv.org/pdf/1511.05644.pdf) combines ideas from two main generative models, autoencoders and generative adversarial networks. This idea was originally proposed by Alireza Makhzani et al(2005) and proposed for drug discovery application in the [druGAN](https://pubs.acs.org/doi/abs/10.1021/acs.molpharmaceut.7b00346) paper.\n",
        "\n",
        "![link text](https://pubs.acs.org/na101/home/literatum/publisher/achs/journals/content/mpohbp/2017/mpohbp.2017.14.issue-9/acs.molpharmaceut.7b00346/20170829/images/medium/mp-2017-00346k_0007.gif)\n",
        "\n",
        "Let's dissect the architecture a bit.\n",
        "Just like the usual generative adversarial network, AAEs have a generator and a discriminator.  \n",
        "- The generator is an autoencoder and that means, its made up of an encoder and a decoder. The encoder takes the input data and learns a compressed representation for it. \n",
        "- The decoder of the generator takes the latent code and attempts to reconstruct the original data from it just as the autoencoder does.\n",
        "- The discriminator is a simple network that also makes sure that the latent code learnt by the encoder is from some prior distribution. \n",
        "- For instance, if we want to impose a gaussian distribution on the latent code, we simply sample from the gaussian distribution as a prior. This makes it easy for us to generate data by simply sampling from a gaussian distribution and reconstructing with the decoder.\n",
        "\n",
        "Then the discriminator has the task of detecting whether a given input comes from the prior distribution or from the encoder. This game continues till \n",
        "* the generator's encoder gets better at learning a latent code that comes from the prior distribution\n",
        "- the decoder gets better at reconstructing the data from the input latent code\n",
        "- The discriminator gets better at differentiating between samples that come from the prior and ones that comes from the encoder.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5iaWw15cxW-"
      },
      "source": [
        "Training the adversarial autoencoder is done in 2 phases; the reconstruction phase and the regularisation phase.\n",
        "\n",
        "- In the reconstruction phase, the generator is trained to minimize reconstruction error.\n",
        "- In the regularization phase, the discriminator is trained to minimize its discriminatory loss and also the encoder is trained to produce a latent code that looks more and more like one that comes from the prior distribution.\n",
        "\n",
        "\n",
        "Now, lets implement the various components of the AAE.\n",
        "- First we create an encoder, a decoder for the generator\n",
        "  - The encoder takes in input SMILES data to produce the latent code\n",
        "  - The decoder accepts the latent code and produces a distribution of the number of unique characters in the SMILES dataset. A decoding strategy is then needed to convert the softmax distribution to text or character sequences. Some of the decoding strategies are: greedy search, beam search, temperature sampling, top-k sampling etc.\n",
        "\n",
        "- Next we create a discriminator.\n",
        "\n",
        "\n",
        "NB: You could replace the autoencoder with a variational autoencoder and in this case the generator will be trained the same way, VAEs are trained with KL objective."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sziy523DyJMR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "2ea584be-772e-4d55-fc8c-107f766a23b3"
      },
      "source": [
        "def encoder_model(num_chars, embedding_dim, max_seq_len, latent_dim, n_units):\n",
        "\n",
        "  '''\n",
        "  Encoder \n",
        "\n",
        "  Inputs\n",
        "    num_chars (int)      : Number of unique characters in dataset\n",
        "    embedding_dim (int)  : Embedding dimension\n",
        "    max_seq_len (int)    : max sequence length\n",
        "    latent_dim (int)     : latent dimension\n",
        "    n_gru_units (int)    : number of gru units\n",
        "\n",
        "  Outputs\n",
        "    (Keras Model Object) : takes data inputs and returns parameters of learned latent distribution \n",
        "  '''\n",
        "\n",
        "  inputs = Input(shape = (max_seq_len, ))\n",
        "  embedding = Embedding(num_chars, embedding_dim, input_length=max_seq_len, mask_zero=True)(inputs)\n",
        "  x = Bidirectional(LSTM(n_units))(embedding)\n",
        "  x = Dense(latent_dim*2, activation='relu')(x)\n",
        "  z = Dense(latent_dim)(x)\n",
        "\n",
        "\n",
        "  # Uncomment this part to do variational \n",
        "  # --------------------------------------\n",
        "  # mu = Dense(latent_dim)(x)\n",
        "  # sigma = Dense(latent_dim)(x)\n",
        "  # model = Model(inputs, outputs = [mu, sigma])\n",
        "\n",
        "  model = Model(inputs, z) # comment out if doing autoencoder\n",
        "  \n",
        "  return model\n",
        "\n",
        "plot_model(encoder_model(num_chars, embedding_dim, max_seq_len, latent_dim, n_units), dpi=70)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLN6VvMFyJKL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "5cc5097b-168d-4435-ec28-7acc2da96795"
      },
      "source": [
        "def decoder_model(num_chars, max_seq_len, latent_dim, n_units):\n",
        "\n",
        "  \"\"\"\n",
        "  Decoder \n",
        "\n",
        "  Inputs\n",
        "    num_chars (int)      : Number of unique characters in dataset\n",
        "    max_seq_len (int)    : max sequence length\n",
        "    latent_dim (int)     : latent dimension\n",
        "    n_gru_units (int)    : number of gru units\n",
        "\n",
        "  Outputs\n",
        "    (Keras Model Object) : takes latent vectors as inputs and returns a \n",
        "                           softmax distribution over character set \n",
        "  \"\"\"\n",
        "\n",
        "  inputs = Input(shape = (latent_dim))\n",
        "  x = RepeatVector(max_seq_len)(inputs)\n",
        "  x = LSTM(n_units, return_sequences=True)(x)\n",
        "  output = TimeDistributed(Dense(num_chars, activation='softmax'))(x)\n",
        "  model = Model(inputs, output)\n",
        "  \n",
        "  return model\n",
        "\n",
        "plot_model(decoder_model(num_chars, max_seq_len, latent_dim, n_units), dpi=70)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWoiaAYmyJDi"
      },
      "source": [
        "# Uncomment to do variational\n",
        "\n",
        "# def reparameterize(inputs):\n",
        "\n",
        "  \n",
        "#   \"\"\"\n",
        "#   Reparameterization function--> takes mean and sigma and reparameterize with samples\n",
        "#    drawn from a standard normal distribution with mean 0 and standard deviation 1. \n",
        "\n",
        "#   Inputs:\n",
        "#    (mu, sigma): mean and standard deviation \n",
        "\n",
        "#   Output:\n",
        "#     z (matrix, size (batch_dim, latent_dim)): latent vectors \n",
        "\n",
        "#    \"\"\"\n",
        "#   mu, sigma = inputs\n",
        "#   n_samples = tf.shape(mu)[0]\n",
        "#   dim = tf.shape(mu)[1]\n",
        "#   eps = random_normal((n_samples, dim))\n",
        "  \n",
        "#   return mu + tf.exp(0.5*sigma) * eps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvFTD7kG9dTI"
      },
      "source": [
        "# Uncomment to do variational\n",
        "# def kl_divergence_loss(mu, sigma):\n",
        "  \n",
        "#   \"\"\" \n",
        "#   Computes the Kullback-Leibler Divergence (KLD) loss\n",
        "#   Inputs\n",
        "#     inputs:  batch from the dataset\n",
        "#     outputs: Output from the sample_z function/ layer\n",
        "#     mu:      mean\n",
        "#     sigma:   standard deviation\n",
        "\n",
        "#   Outputs:\n",
        "#     KL Divergence loss\n",
        "#   \"\"\"\n",
        "\n",
        "#   kl_loss = 1 + sigma - tf.square(mu) - tf.math.exp(sigma)\n",
        "#   kl_loss = tf.reduce_mean(kl_loss) * -0.5\n",
        "\n",
        "#   return kl_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttPHwNP0V35c"
      },
      "source": [
        "def autoencoder_model(encoder, decoder, max_seq_len):\n",
        "\n",
        "  \n",
        "  \"\"\"\n",
        "  Biulds a complete VAE model\n",
        "\n",
        "  Inputs\n",
        "    encoder: the encoder model\n",
        "    decoder: the decoder model\n",
        "    max_seq_len: length of sequence batch\n",
        "\n",
        "  Output:\n",
        "    the complete VAE model\n",
        "  \"\"\"\n",
        "\n",
        "  # set the inputs\n",
        "  inputs = tf.keras.layers.Input(shape=(max_seq_len, ))\n",
        "\n",
        "  # Uncomment to do variational\n",
        "  # mu, sigma = encoder(inputs)    # get mu and sigma from the encoder output\n",
        "  # z = Lambda(reparameterize)(([mu, sigma]))\n",
        "  z = encoder(inputs)\n",
        "  reconstructed = decoder(z)    # get reconstructed output from the decoder\n",
        "\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=reconstructed) # define the inputs and outputs of the VAE\n",
        "\n",
        "  # add the KL loss\n",
        "  # loss = kl_divergence_loss(mu, sigma)\n",
        "  # model.add_loss(loss)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXEYjYcE8BAp"
      },
      "source": [
        "def generator_model(encoder, discriminator, max_seq_len):\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=(max_seq_len, ))\n",
        "  z = encoder(inputs)\n",
        "  disc_pred = discriminator(z)\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=disc_pred) \n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u96_j9mvVJjm"
      },
      "source": [
        "def sample_prior(batch_size, latent_dim):\n",
        "\n",
        "  \"\"\"\n",
        "  Sample prior       :  Sample for random normal distribution\n",
        "  Inputs:\n",
        "    batch_size (int) : number of samples to generate\n",
        "    latent_dim (int) : latent dimension\n",
        "\n",
        "  Outputs\n",
        "    samples from normal distribution (size = (batch_size, latent_dim))\n",
        "  \"\"\"\n",
        "\n",
        "  return random_normal((batch_size, latent_dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgYT5T2ct3Q6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "2c4f6f34-ab35-44ae-9cdc-ddd512f7c24b"
      },
      "source": [
        "def discriminator_model(latent_dim):\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  Define discriminator\n",
        "  Inputs\n",
        "    latent_dim: latent dimension\n",
        "\n",
        "  Outputs\n",
        "    discriminator model \n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  inputs = Input(shape=(latent_dim, ))\n",
        "  x = Dense(64)(inputs)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  x = Dense(32)(x)\n",
        "  x = LeakyReLU(0.2)(x)\n",
        "  outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "  \n",
        "  model = Model(inputs, outputs)\n",
        "  \n",
        "  return model\n",
        "\n",
        "plot_model(discriminator_model(latent_dim), dpi=70)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWBf20t4oYFH"
      },
      "source": [
        "Now, lets define our loss functions and optimizers. We can use SGD, Adam or other optimizers. Its great to try things :)\n",
        "- For losses, we use the sparse categorical cross entropy loss for the reconstruction of sparse categorical SMILES inputs and the reconstruction. This will be for the autoencoder (generator). \n",
        "- For the discriminator, we'll use a binary cross entropy loss since the discriminator is only trying to distinguish between two class (fake or real)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8jnxfBIW-VX"
      },
      "source": [
        "# Define our loss functions and optimizers\n",
        "gen_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "disc_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "ae_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "loss_metric = tf.keras.metrics.Mean()\n",
        "\n",
        "spce_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "bce_loss = tf.keras.losses.BinaryCrossentropy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cli0o9ODheqA"
      },
      "source": [
        "# Initialize model\n",
        "def init_models(num_chars, embedding_dim, max_seq_len, latent_dim, n_units):\n",
        "  \"\"\"Initialize models \"\"\"\n",
        "  #init encoder & decoder\n",
        "  encoder = encoder_model(num_chars, embedding_dim, max_seq_len, latent_dim, n_units)\n",
        "  decoder = decoder_model(num_chars, max_seq_len, latent_dim, n_units)\n",
        "\n",
        "  # Init discriminator and generator (generator --> discriminator)\n",
        "  discriminator = discriminator_model(latent_dim)\n",
        "  generator = generator_model(encoder, discriminator, max_seq_len)\n",
        "\n",
        "  # Init generator / autoencoder = encoder + decoder\n",
        "  autoencoder = autoencoder_model(encoder, decoder, max_seq_len)\n",
        "\n",
        "  return encoder, decoder, generator, discriminator, autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmoutjmxYSOT"
      },
      "source": [
        "encoder, decoder, generator, discriminator, autoencoder = init_models(num_chars, embedding_dim, max_seq_len, latent_dim, n_units)\n",
        "discriminator.trainable = False "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnjxPAVYp11d"
      },
      "source": [
        "In the training loop, we take a minibatch of the data at a time, sample an equivalent number of samples as the batch of data and update the network parameters alternatingly in the reconstruction and regularization phases. Notice that we set the `discriminator.trainables` to True when training the discriminator and False when training only the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4XDVewqcdg9",
        "outputId": "41152c58-bbec-46ca-e51f-fc8dc3f01fb5"
      },
      "source": [
        "# Training loop. \n",
        "\n",
        "\n",
        "epochs = 100 # Set the number of training epochs\n",
        "disc_loss = []\n",
        "gen_loss = []\n",
        "avg_recon_loss = []\n",
        "for epoch in range(epochs):\n",
        "  # iterate over the batches of the dataset.\n",
        "  for step, batch in enumerate(train_dataset):\n",
        "\n",
        "    #  RECONSTRUCTION PHASE\n",
        "    # -----------------------------------------------------------------------------------------------------------------\n",
        "    # -----------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    with tf.GradientTape() as rtape:\n",
        "      noise = tf.random.normal(shape=[batch_size, latent_dim])\n",
        "      generator.trainable = True\n",
        "      # feed a batch to the VAE model\n",
        "      reconstructed = autoencoder(batch)                                             # Get a batch of the training examples and feed to the model\n",
        "    \n",
        "      recon_loss = spce_loss(batch, reconstructed)                                   # compute the reconstruction loss between data and reconstruction\n",
        "      # recon_loss += sum(generator.losses)                                          # add the KL Divergence loss to the reconstruction loss for vae\n",
        "    \n",
        "    recon_grads = rtape.gradient(recon_loss, autoencoder.trainable_weights)          # get the gradients with respect to the weights \n",
        "    ae_optimizer.apply_gradients(zip(recon_grads, autoencoder.trainable_weights))    # Update the weights with gradients\n",
        "\n",
        "    loss_metric(recon_loss) # compute the mean of losses\n",
        "\n",
        "\n",
        "    # REGULARIZATION PHASE\n",
        "    # -----------------------------------------------------------------------------------------------------------------\n",
        "    # -----------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    # Discriminator Training\n",
        "    with tf.GradientTape() as dtape:\n",
        "      noise = sample_prior(batch_size, latent_dim)                                   # Sample from the prior distribution\n",
        "      # z = encoder(batch)                                                           # Generate the latent distribution with the encoder of the generator\n",
        "      # concat_data = tf.concat([noise, z], axis =0)                                 # Concatenate both the prior distribution and latent \n",
        "      discriminator.trainable = True  \n",
        "                                                                                     # Set discriminator's weights as trainable \n",
        "      latent_pred = generator(batch)\n",
        "      latent_labels = tf.zeros_like(latent_pred)\n",
        "\n",
        "      prior_pred = discriminator(noise)                                              # Predict labels for prior\n",
        "      prior_labels = tf.ones_like(prior_pred)                                        # Make labels for prior\n",
        "      latent_loss = bce_loss(latent_labels, latent_pred)                             # compute crossentropy loss for latent\n",
        "      prior_loss = bce_loss(prior_labels, prior_pred)                                # compute crossentropy loss for prior \n",
        "\n",
        "      disc_loss = (latent_loss + prior_loss)/2\n",
        "\n",
        "    disc_grads = dtape.gradient(disc_loss, discriminator.trainable_weights)          # Compute gradients wrt discriminator weights\n",
        "    disc_optimizer.apply_gradients(zip(disc_grads, discriminator.trainable_weights)) # Update weights\n",
        "\n",
        "    \n",
        "    # Generator training\n",
        "    with tf.GradientTape() as gtape:\n",
        "\n",
        "      discriminator.trainable = False                                                # Set discriminator weights to not trainable  \n",
        "      batch_pred = generator(batch)                                                  # Predict labels for noise\n",
        "      labels = tf.ones_like(batch_pred)                                              # Make labels to fool discriminator\n",
        "      gen_loss = bce_loss(labels, batch_pred)                                        # Get loss from discriminator\n",
        "\n",
        "    gen_grads = gtape.gradient(gen_loss, generator.trainable_weights)\n",
        "    gen_optimizer.apply_gradients(zip(gen_grads, generator.trainable_weights))\n",
        "\n",
        "\n",
        "    # Show outputs at every 50 steps\n",
        "    if step % 50 == 0:\n",
        "      print('Epoch: %s\\t step: %s \\n average recon loss: %s \\t disc loss: %s \\t gen loss: %s' % (epoch, step, loss_metric.result().numpy(), disc_loss.numpy(), gen_loss.numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\t step: 0 \n",
            " average recon loss: 3.4974911 \t disc loss: 0.7079675 \t gen loss: 0.6934743\n",
            "Epoch: 0\t step: 50 \n",
            " average recon loss: 2.8911037 \t disc loss: 0.6999729 \t gen loss: 0.61236745\n",
            "Epoch: 1\t step: 0 \n",
            " average recon loss: 2.7160344 \t disc loss: 0.46787906 \t gen loss: 1.1719172\n",
            "Epoch: 1\t step: 50 \n",
            " average recon loss: 2.3852465 \t disc loss: 0.40495592 \t gen loss: 1.4087272\n",
            "Epoch: 2\t step: 0 \n",
            " average recon loss: 2.3235176 \t disc loss: 0.40513408 \t gen loss: 1.29237\n",
            "Epoch: 2\t step: 50 \n",
            " average recon loss: 2.1520147 \t disc loss: 0.51447034 \t gen loss: 0.8620775\n",
            "Epoch: 3\t step: 0 \n",
            " average recon loss: 2.1100712 \t disc loss: 0.5657344 \t gen loss: 0.7221291\n",
            "Epoch: 3\t step: 50 \n",
            " average recon loss: 1.996597 \t disc loss: 0.5972969 \t gen loss: 0.5767285\n",
            "Epoch: 4\t step: 0 \n",
            " average recon loss: 1.9721652 \t disc loss: 0.65518636 \t gen loss: 0.5386651\n",
            "Epoch: 4\t step: 50 \n",
            " average recon loss: 1.8981756 \t disc loss: 0.7795193 \t gen loss: 0.41742885\n",
            "Epoch: 5\t step: 0 \n",
            " average recon loss: 1.8820035 \t disc loss: 0.8133555 \t gen loss: 0.36492974\n",
            "Epoch: 5\t step: 50 \n",
            " average recon loss: 1.8317606 \t disc loss: 0.6473804 \t gen loss: 0.66091293\n",
            "Epoch: 6\t step: 0 \n",
            " average recon loss: 1.8196397 \t disc loss: 0.58586323 \t gen loss: 0.83819455\n",
            "Epoch: 6\t step: 50 \n",
            " average recon loss: 1.7963787 \t disc loss: 0.81886894 \t gen loss: 0.5114985\n",
            "Epoch: 7\t step: 0 \n",
            " average recon loss: 1.7870166 \t disc loss: 0.6826047 \t gen loss: 0.6142771\n",
            "Epoch: 7\t step: 50 \n",
            " average recon loss: 1.7631471 \t disc loss: 0.6606083 \t gen loss: 0.8706831\n",
            "Epoch: 8\t step: 0 \n",
            " average recon loss: 1.7547292 \t disc loss: 0.6201305 \t gen loss: 0.95284605\n",
            "Epoch: 8\t step: 50 \n",
            " average recon loss: 1.7269154 \t disc loss: 0.6124785 \t gen loss: 0.9325473\n",
            "Epoch: 9\t step: 0 \n",
            " average recon loss: 1.7203689 \t disc loss: 0.6078937 \t gen loss: 0.960752\n",
            "Epoch: 9\t step: 50 \n",
            " average recon loss: 1.6975763 \t disc loss: 0.8416256 \t gen loss: 0.41337472\n",
            "Epoch: 10\t step: 0 \n",
            " average recon loss: 1.6906812 \t disc loss: 0.8755626 \t gen loss: 0.41706225\n",
            "Epoch: 10\t step: 50 \n",
            " average recon loss: 1.6721202 \t disc loss: 1.1160471 \t gen loss: 0.30843437\n",
            "Epoch: 11\t step: 0 \n",
            " average recon loss: 1.6680367 \t disc loss: 1.1006896 \t gen loss: 0.3268825\n",
            "Epoch: 11\t step: 50 \n",
            " average recon loss: 1.6542066 \t disc loss: 0.82811856 \t gen loss: 0.6176826\n",
            "Epoch: 12\t step: 0 \n",
            " average recon loss: 1.6514475 \t disc loss: 0.8074103 \t gen loss: 0.6948464\n",
            "Epoch: 12\t step: 50 \n",
            " average recon loss: 1.6399472 \t disc loss: 0.8873035 \t gen loss: 0.5623003\n",
            "Epoch: 13\t step: 0 \n",
            " average recon loss: 1.6383404 \t disc loss: 0.89190793 \t gen loss: 0.5387088\n",
            "Epoch: 13\t step: 50 \n",
            " average recon loss: 1.6287535 \t disc loss: 0.8226514 \t gen loss: 0.6974971\n",
            "Epoch: 14\t step: 0 \n",
            " average recon loss: 1.6250354 \t disc loss: 0.769778 \t gen loss: 0.8184235\n",
            "Epoch: 14\t step: 50 \n",
            " average recon loss: 1.6146747 \t disc loss: 0.8411925 \t gen loss: 0.61115897\n",
            "Epoch: 15\t step: 0 \n",
            " average recon loss: 1.6110235 \t disc loss: 0.82575786 \t gen loss: 0.67185175\n",
            "Epoch: 15\t step: 50 \n",
            " average recon loss: 1.5982038 \t disc loss: 0.7278886 \t gen loss: 0.7664988\n",
            "Epoch: 16\t step: 0 \n",
            " average recon loss: 1.5953411 \t disc loss: 0.6901941 \t gen loss: 0.7765105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO0tJU3CN4a6"
      },
      "source": [
        "generate_random_smiles(decoder, 10, latent_dim, decoding_strategy='temp', temperature=0.5) # Lets generate some random samples with the trained decoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StlA4mIVX4QN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}