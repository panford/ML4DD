{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Notebook_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panford/ML4DD/blob/main/Notebook_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkNDzYZyEQ2Y"
      },
      "source": [
        "# Generative Models for Molecule Generation\n",
        "( Using VAE - TensorFlow/ keras implementation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J95ZeAUHPOD7"
      },
      "source": [
        "**Author**: Kobby Panford-Quainoo [(panford.github.io)](https://panford.github.io)\n",
        "\n",
        "**Institution:** African Institute for Mathematical Sciences - African Masters in Machine Intelligence (AIMS-AMMI)\n",
        "\n",
        "**Workshop:** International E-workshop on Machine Learning for Drug Discovery, India (05/21)\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPbswxV-rM0C"
      },
      "source": [
        "In this tutorial, we will look at how to generate molecules from the SMILES dataset using variational Autoencoders (VAEs). Let's begin by installing condalab which will allow us to later install RDKit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HCDLVxByFhJ",
        "outputId": "56f0202e-c600-43d2-87ee-ef75918bfa42"
      },
      "source": [
        "#@title Install condalab: We need to install condalab in order to install RDKits with Anaconda\n",
        "!pip install -q condacolab\n",
        "\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "!conda install -q rdkit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:31\n",
            "ðŸ” Restarting kernel...\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.74.0               |   py37h6dcda5c_3         342 KB  conda-forge\n",
            "    boost-cpp-1.74.0           |       hc6e9bd1_3        16.3 MB  conda-forge\n",
            "    cairo-1.16.0               |    h6cf1ce9_1008         1.5 MB  conda-forge\n",
            "    conda-4.10.1               |   py37h89c1867_0         3.1 MB  conda-forge\n",
            "    cycler-0.10.0              |             py_2           9 KB  conda-forge\n",
            "    fontconfig-2.13.1          |    hba837de_1005         357 KB  conda-forge\n",
            "    freetype-2.10.4            |       h0708190_1         890 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    h0b5b191_1005         3.6 MB  conda-forge\n",
            "    greenlet-1.1.0             |   py37hcd2ae1e_0          83 KB  conda-forge\n",
            "    importlib-metadata-4.2.0   |   py37h89c1867_0          30 KB  conda-forge\n",
            "    jpeg-9d                    |       h36c2ea0_0         264 KB  conda-forge\n",
            "    kiwisolver-1.3.1           |   py37h2527ec5_1          78 KB  conda-forge\n",
            "    libblas-3.9.0              |       9_openblas          11 KB  conda-forge\n",
            "    libcblas-3.9.0             |       9_openblas          11 KB  conda-forge\n",
            "    libgfortran-ng-9.3.0       |      hff62375_19          22 KB  conda-forge\n",
            "    libgfortran5-9.3.0         |      hff62375_19         2.0 MB  conda-forge\n",
            "    libglib-2.68.2             |       h3e27bee_0         3.1 MB  conda-forge\n",
            "    liblapack-3.9.0            |       9_openblas          11 KB  conda-forge\n",
            "    libopenblas-0.3.15         |pthreads_h8fe5266_1         9.2 MB  conda-forge\n",
            "    libpng-1.6.37              |       h21135ba_2         306 KB  conda-forge\n",
            "    libtiff-4.0.10             |    hc3755c2_1005         602 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h7f98852_1000          28 KB  conda-forge\n",
            "    libxcb-1.13                |    h7f98852_1003         395 KB  conda-forge\n",
            "    matplotlib-base-3.4.2      |   py37hdd32ed1_0         7.2 MB  conda-forge\n",
            "    numpy-1.20.3               |   py37h038b26d_1         5.7 MB  conda-forge\n",
            "    olefile-0.46               |     pyh9f0ad1d_1          32 KB  conda-forge\n",
            "    openssl-1.1.1k             |       h7f98852_0         2.1 MB  conda-forge\n",
            "    pandas-1.2.4               |   py37h219a48f_0        11.8 MB  conda-forge\n",
            "    pcre-8.44                  |       he1b5a44_0         261 KB  conda-forge\n",
            "    pillow-6.2.1               |   py37h6b7be26_0         637 KB  conda-forge\n",
            "    pixman-0.40.0              |       h36c2ea0_0         627 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h36c2ea0_1001           5 KB  conda-forge\n",
            "    pycairo-1.20.0             |   py37hfff247e_1          77 KB  conda-forge\n",
            "    pyparsing-2.4.7            |     pyh9f0ad1d_0          60 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    pytz-2021.1                |     pyhd8ed1ab_0         239 KB  conda-forge\n",
            "    rdkit-2021.03.2            |   py37haf5a968_0        38.3 MB  conda-forge\n",
            "    reportlab-3.5.67           |   py37h69800bb_0         2.4 MB  conda-forge\n",
            "    sqlalchemy-1.4.15          |   py37h5e8e339_0         2.2 MB  conda-forge\n",
            "    tornado-6.1                |   py37h5e8e339_1         646 KB  conda-forge\n",
            "    typing_extensions-3.7.4.3  |             py_0          25 KB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h7f98852_1002          27 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h7f98852_0          58 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    hd9c2040_1000          26 KB  conda-forge\n",
            "    xorg-libx11-1.7.1          |       h7f98852_0         946 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h7f98852_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h7f98852_0          19 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h7f98852_1          54 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h7f98852_1003          32 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h7f98852_1002           9 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h7f98852_1002          28 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h7f98852_1007          73 KB  conda-forge\n",
            "    zipp-3.4.1                 |     pyhd8ed1ab_0          11 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       115.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.74.0-py37h6dcda5c_3\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.74.0-hc6e9bd1_3\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-h6cf1ce9_1008\n",
            "  cycler             conda-forge/noarch::cycler-0.10.0-py_2\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-hba837de_1005\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-h0b5b191_1005\n",
            "  greenlet           conda-forge/linux-64::greenlet-1.1.0-py37hcd2ae1e_0\n",
            "  importlib-metadata conda-forge/linux-64::importlib-metadata-4.2.0-py37h89c1867_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9d-h36c2ea0_0\n",
            "  kiwisolver         conda-forge/linux-64::kiwisolver-1.3.1-py37h2527ec5_1\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-9_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-9_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-9.3.0-hff62375_19\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-9.3.0-hff62375_19\n",
            "  libglib            conda-forge/linux-64::libglib-2.68.2-h3e27bee_0\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-9_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.15-pthreads_h8fe5266_1\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.0.10-hc3755c2_1005\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h7f98852_1003\n",
            "  matplotlib-base    conda-forge/linux-64::matplotlib-base-3.4.2-py37hdd32ed1_0\n",
            "  numpy              conda-forge/linux-64::numpy-1.20.3-py37h038b26d_1\n",
            "  olefile            conda-forge/noarch::olefile-0.46-pyh9f0ad1d_1\n",
            "  pandas             conda-forge/linux-64::pandas-1.2.4-py37h219a48f_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
            "  pillow             conda-forge/linux-64::pillow-6.2.1-py37h6b7be26_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.40.0-h36c2ea0_0\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.20.0-py37hfff247e_1\n",
            "  pyparsing          conda-forge/noarch::pyparsing-2.4.7-pyh9f0ad1d_0\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  pytz               conda-forge/noarch::pytz-2021.1-pyhd8ed1ab_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2021.03.2-py37haf5a968_0\n",
            "  reportlab          conda-forge/linux-64::reportlab-3.5.67-py37h69800bb_0\n",
            "  sqlalchemy         conda-forge/linux-64::sqlalchemy-1.4.15-py37h5e8e339_0\n",
            "  tornado            conda-forge/linux-64::tornado-6.1-py37h5e8e339_1\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-3.7.4.3-py_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h7f98852_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h7f98852_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-hd9c2040_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.7.1-h7f98852_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h7f98852_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h7f98852_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h7f98852_1\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h7f98852_1003\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h7f98852_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h7f98852_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h7f98852_1007\n",
            "  zipp               conda-forge/noarch::zipp-3.4.1-pyhd8ed1ab_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  conda                                4.9.2-py37h89c1867_0 --> 4.10.1-py37h89c1867_0\n",
            "  openssl                                 1.1.1j-h7f98852_0 --> 1.1.1k-h7f98852_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2UckLll9duz"
      },
      "source": [
        "## Import libraries and Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLfRRpxPyJhP"
      },
      "source": [
        "# Imports\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from rdkit.Chem import Descriptors, QED\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.backend import random_normal\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Lambda, Input, RepeatVector, TimeDistributed\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Concatenate\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "tf.random.set_seed(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkK-ce_zF7B4"
      },
      "source": [
        "Before we begin, lets define some utility functions that will help us process, encode and decode texts as well as compute molecular properties/ descriptors we'll need later in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzQPjVECyJe-",
        "cellView": "form"
      },
      "source": [
        "#@title Utility functions for SMILES property computation\n",
        "# Define utility functions here\n",
        "def compute_smile_prop(smile):\n",
        "\n",
        "  \"\"\" \n",
        "  Compute smiles properties (MolWt, LogP, QED)\n",
        "\n",
        "  Inputs:\n",
        "    smile (str, list, tuple) : A sequence or list of sequences of smiles \n",
        "                                data whose properties needs to be computed\n",
        "  Output:\n",
        "    props (list)  :   Computed properties\n",
        "  \n",
        "  \"\"\"\n",
        "\n",
        "  def compute_for_one(smi):\n",
        "\n",
        "    \"\"\"\n",
        "    Computes properties for a single smile sequence\n",
        "\n",
        "    Inputs \n",
        "      smi (str) : A sequence of smile characters\n",
        "    Outputs\n",
        "      prop (list): Computed properties, \"Not exist\" if properties cannot be computed\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        mol=Chem.MolFromSmiles(smi) \n",
        "        prop = [Descriptors.ExactMolWt(mol), Descriptors.MolLogP(mol), QED.qed(mol)]\n",
        "    except:\n",
        "        prop = 'Not exist!'\n",
        "    return prop\n",
        "\n",
        "      \n",
        "  if isinstance(smile, (list, tuple)):\n",
        "    all_list = []\n",
        "    for s in list(smile):\n",
        "      all_list.append(compute_for_one(s))\n",
        "    props = all_list\n",
        "\n",
        "  elif isinstance(smile, str):\n",
        "    props = compute_for_one(smile) \n",
        "  else:\n",
        "    print(f\"Input must be a string or list, Instead got {type(smile)}\")\n",
        "    \n",
        "  return props\n",
        "\n",
        "def canonicalize(smile):\n",
        "  \"\"\"Function to canonicalise smiles inputs sequence\"\"\"\n",
        "\n",
        "  return Chem.MolToSmiles(Chem.MolFromSmiles(smile))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnMtyHg11zQe",
        "cellView": "form"
      },
      "source": [
        "#@title Utility functions for decoding sequences\n",
        "def greedy_search():\n",
        "  \"\"\"\n",
        "  A decoder algorithm to retrieve sequences from decoder output\n",
        "\n",
        "  Inputs\n",
        "    inputs (tf-tensor): Output from decoder, size (batch, max_seq_len, num_chars)\n",
        "  \n",
        "  Outputs\n",
        "    seq of greedily decoded sequences\n",
        "  \"\"\"\n",
        "  def decode(preds):\n",
        "    return np.argmax(preds).tolist()\n",
        "\n",
        "  return decode\n",
        "\n",
        "\n",
        "\n",
        "def temperature_sampling(temperature):\n",
        "  \"\"\"\n",
        "  Temperature sampling wrapper function\n",
        "\n",
        "  This wrapper function will allow us use the temperature sampling strategy to decode our predicted sequences\n",
        "  \"\"\"\n",
        "  def softmax(z):\n",
        "    \"\"\"Softmax function \"\"\"\n",
        "    return np.exp(z)/sum(np.exp(z))\n",
        "\n",
        "  def decode(preds):\n",
        "\n",
        "    \"\"\" \n",
        "    Decoder using temperature \n",
        "    \"\"\"\n",
        "\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    reweighted_preds = softmax(preds)\n",
        "    probs = np.random.multinomial(1, reweighted_preds, 1)\n",
        "\n",
        "    return np.argmax(probs)\n",
        "\n",
        "  return decode\n",
        "\n",
        "\n",
        "\n",
        "def decode_preds(preds, d_strategy=\"temp\", **decoder_params):\n",
        "\n",
        "  \"\"\"Decoding function: call this with decoder prediction\n",
        "  Inputs\n",
        "    preds (batch_size, max_seq_len, num_chars): softmax prediction from decoder model\n",
        "    d_strategy (str):      Strategy to use for prediction\n",
        "  \"\"\"\n",
        "\n",
        "  \n",
        "  if d_strategy == \"temp\":\n",
        "    temperature = decoder_params.get('temperature') or 0.5\n",
        "    strategy = temperature_sampling(temperature)    \n",
        "    print('Decoding strategy: ', \"Temperature Sampling (%s) \"%temperature)\n",
        "\n",
        "  elif d_strategy == 'greedy':\n",
        "    strategy = greedy_search()\n",
        "    print('Decoding strategy: ', \"Greedy Search\")\n",
        "  print(\"*\"*8)\n",
        "\n",
        "  seqs = []\n",
        "  for n in range(preds.shape[0]):\n",
        "    batch = []\n",
        "    for l in range(preds.shape[1]):\n",
        "      batch.append(strategy(preds[n,l,:]))\n",
        "    seqs.append(batch)\n",
        "  decoded_seq = tokenizer.sequences_to_texts(unpad(list(seqs)))\n",
        "  seq = [s.replace(\" \",\"\") for s in decoded_seq]\n",
        "\n",
        "  return seq\n",
        "\n",
        "\n",
        "def generate_smiles_from_prior(model, prior, decoding_strategy = \"temp\", **decoder_params):\n",
        "  \n",
        "  \"\"\"\n",
        "  Generates smiles samples from prior\n",
        "\n",
        "  Inputs\n",
        "    batch_size: Batch size of samples to generate\n",
        "    latent_dim: Latent dimension \n",
        "\n",
        "  outputs\n",
        "    decoded_seq: Decoded sequence\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  predicted_seq = model.predict(prior)\n",
        "\n",
        "  return decode_preds(predicted_seq, decoding_strategy, **decoder_params)\n",
        "\n",
        "\n",
        "def unpad(input_tokens):\n",
        "  \"\"\"Function for unpadding tokens\n",
        "  Inputs\n",
        "    input_tokens  : list of input tokens\n",
        "  Outputs\n",
        "    unpadded tokens (list)\n",
        "  \"\"\"\n",
        "\n",
        "  unpadded = []\n",
        "  for i in range(len(input_tokens)):\n",
        "    unpadded_list = [token for token in input_tokens[i] if token !=0]\n",
        "    unpadded.append(unpadded_list)\n",
        "\n",
        "  return unpadded\n",
        "\n",
        "\n",
        "def generate_random_smiles(model, batch_size, latent_dim, decoding_strategy, **decoder_params):\n",
        "  \n",
        "  \"\"\"\n",
        "  Generates smiles samples from random normal samples\n",
        "\n",
        "  Inputs\n",
        "    batch_size: Batch size of samples to generate\n",
        "    latent_dim: Latent dimension \n",
        "    model     : model to predict from prior\n",
        "\n",
        "  outputs\n",
        "    decoded_seq: Decoded sequence\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  prior = tf.random.normal(shape=[batch_size, latent_dim],)\n",
        "\n",
        "  return generate_smiles_from_prior(model, prior, decoding_strategy, **decoder_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_Zir0yS9uYh"
      },
      "source": [
        "## Get and Prepare dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt27JVZc90gh"
      },
      "source": [
        "In this tutorial, we will use the SMILES (Simplified Molecular Input Line Entry System) dataset which is made up of molecules in sequences of character notations representing both the chemical elements present as well as the bonds that exists between them. eg, CH3CH3, CC etc. We'll print out a few more strings in the next cells. read more[1](https://archive.epa.gov/med/med_archive_03/web/html/smiles.html#:~:text=SMILES%20(Simplified%20Molecular%20Input%20Line,easily%20learned%20and%20flexible%20notation.), [2](https://www.semanticscholar.org/paper/SMILES%2C-a-chemical-language-and-information-system.-Weininger/3f7983818b76a5f1b5daf9b605877ed401c8e73c)\n",
        "\n",
        "We can compute specific properties such as the *Exact molecular weights* of molecules using RDKit. This will be useful to us later where they'd be used as targets for conditional generation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blFOgyB97xzq",
        "outputId": "0b0f4865-efd4-4d15-94a2-3ebfb46bfcd3"
      },
      "source": [
        "!git clone https://github.com/panford/ML4DD.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ML4DD' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZDjMGcx8uOQ"
      },
      "source": [
        "path_to_data = \"/content/ML4DD/data/smiles.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_zbzBk8yJaS"
      },
      "source": [
        "#Lets get the data path\n",
        "# path_to_data = \"/content/drive/MyDrive/molecule_vae/ZINC_310k.csv\"\n",
        "# path_to_data = \"/content/drive/MyDrive/smiles.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtRBx1EwyJX-"
      },
      "source": [
        "# Load up data from path\n",
        "\n",
        "smiles_data = pd.read_csv(path_to_data, header = None)\n",
        "smiles_data = smiles_data[0][:2000] # THis is very huge so select the amount of data you can work with effectively"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyFGJURO6Qc4",
        "outputId": "6a934c92-336e-4ed0-d453-ad5b5dd9975d"
      },
      "source": [
        "smiles_data.head() # Lets take a glance at the data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            C[C@@]1(C(=O)C=C(O1)C(=O)[O-])c2ccccc2\n",
              "1             c1ccc(cc1)C(c2ccccc2)[S@](=O)CC(=O)NO\n",
              "2    CCC[S@](=O)c1ccc2c(c1)[nH]/c(=N\\C(=O)OC)/[nH]2\n",
              "3    CCC[S@](=O)c1ccc2c(c1)[nH]/c(=N/C(=O)OC)/[nH]2\n",
              "4                  CC(C)C[C@@H]1C(=O)N(C(=S)N1)CC=C\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXwoIAI0fquW",
        "outputId": "241dda7e-850e-454d-b6e8-c0ba0189f733"
      },
      "source": [
        "compute_smile_prop(smiles_data[:5].tolist())#.tolist()) # Compute properties for the first 5 datapoints"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[217.05063234791, 0.1348999999999997, 0.7060511028948301],\n",
              " [289.07726434, 2.0300999999999996, 0.6535741974690973],\n",
              " [281.08341234000005, 1.6806999999999999, 0.8968983095288725],\n",
              " [281.08341234000005, 1.6806999999999999, 0.8968983095288725],\n",
              " [212.098334132, 1.3038, 0.5630097133159685]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_4juxCQMM6L"
      },
      "source": [
        "Since the SMILES dataset is made up of strings, we will use some of the tools in Natural Language Processing (NLP) and sequence modelling to learn the high-level structure in these molecular sequences.\n",
        "\n",
        "We'll follow the steps below to get our data ready for learning.\n",
        "\n",
        "1. Tokenize data at the character-level\n",
        "2. Use token indices to create numerical sequences\n",
        "3. Pad data to same length as maximum sequence length (ie. the longest sequence seen so far in the data)\n",
        "4. There are few more things you can do: add special tokens like \\<bos\\> to indicate beginning of sequence, \\<eos\\> for end of sequence etc.\n",
        "5. Add some domain knowledge about the expected characters; if you know the entire set of sequences used in SMILES, you could define a dictionary for them etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ojr7liayJVy"
      },
      "source": [
        "# Create a tokenizer to tokenize the characters in the smiles dataset\n",
        "\n",
        "tokenizer = Tokenizer(filters=None,\n",
        "                      lower=False,\n",
        "                      char_level=True)\n",
        "tokenizer.fit_on_texts(smiles_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXo66f3gyJTR",
        "outputId": "f575c86e-a5ec-426a-9ac1-be9d54285fcf"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'c': 1, 'C': 2, '(': 3, ')': 4, '1': 5, 'O': 6, '2': 7, '[': 8, ']': 9, '=': 10, 'N': 11, '3': 12, 'H': 13, '@': 14, 'n': 15, '+': 16, '4': 17, '-': 18, 'l': 19, '/': 20, 'S': 21, 'F': 22, 's': 23, 'o': 24, '#': 25, '\\\\': 26, 'B': 27, 'r': 28, '5': 29, 'I': 30, 'P': 31, '6': 32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOftFqsu-wMI"
      },
      "source": [
        "def create_padded_data(smiles_):\n",
        "\n",
        "  \"\"\"\n",
        "  Creates numerical dataset from character sequences and pads up to the max sequence length\n",
        "  Inputs\n",
        "    smiles_(list):  lists of sequences from data\n",
        "  Outputs:\n",
        "    (nd.array):     An array of padded sequences up to max sequence length\n",
        "    max_seq_len (int): length of longest sequence in the data\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  x_sequences = [] \n",
        "  \n",
        "  # Loop through each row\n",
        "  for line in smiles_:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0] #Tokenize each row\n",
        "    x_sequences.append(token_list) # append to x_sequences\n",
        "\n",
        "  # pad sequences \n",
        "  max_seq_len = max([len(x) for x in x_sequences]) # Compute max sequence length\n",
        "\n",
        "  return np.array(pad_sequences(x_sequences, maxlen=max_seq_len, padding='pre')), max_seq_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrM3r-RCx-6Y",
        "outputId": "c8a1fe0f-fc32-4fd9-8706-2e278132158d"
      },
      "source": [
        "X, max_seq_len = create_padded_data(smiles_data)\n",
        "X[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  2,  8,  2, 14, 14,  9,  5,  3,  2,  3, 10,  6,\n",
              "        4,  2, 10,  2,  3,  6,  5,  4,  2,  3, 10,  6,  4,  8,  6, 18,  9,\n",
              "        4,  1,  7,  1,  1,  1,  1,  1,  7], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVXZ-AUzyJRJ"
      },
      "source": [
        "num_props = 3             # Number of target properties\n",
        "latent_dim = 100          # Dimension of latent vector \n",
        "batch_size = 32         # Batch size\n",
        "embedding_dim = 200       # Embedding dimension\n",
        "num_chars = len(tokenizer.word_index)+1 # Compute the number of characters or unique tokens\n",
        "                                        # Add one for padding\n",
        "n_units = 96               # Number of recurrent units\n",
        "learning_rate = 0.002    # Learning rate for optimizer\n",
        "rate = tf.Variable(0.0)    # KL annealing rate init (Useful when you want to do KL annealing)\n",
        "annealing_rate = 0.0001    # KL annealing rate      (Useful when you want to do KL annealing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kVbRboU66S0"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(X)  # Create a tensorflow dataset\n",
        "train_dataset = dataset.batch(batch_size).shuffle(1024) # Add batching and shuffling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyB1NaUCOUbE"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Variational Autoencoders (VAEs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HkHQgautBBs"
      },
      "source": [
        "The VAE is one of the most popular deep generative modelling approach used to model complicated data distributions.\n",
        "\n",
        "The VAE is made up of an encoder and a decoder just like an autoencoder except that an autoencoder learng a compact representation for the input data whereas the variational autoencoder learns a distribution. \n",
        "In our specific example, we have an encoder which takes input molecular data/ representation and a latent distribution from which we can sample latent vectors and reconstruct should we need to. This allows us to create new data not observed in the input data which is not possible with the autoencoder which only learns a deterministic latent code.\n",
        "\n",
        "![link text](https://lilianweng.github.io/lil-log/assets/images/vae-gaussian.png) Image from Lilian Weng. Also read more technical details about autoencoders [here](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)\n",
        "\n",
        "\n",
        "\n",
        "1. Encoder - This is a simple network that takes the input data and transforms them into a latent code parameterized by mu and sigma.\n",
        "2. Reparameterization - This is an important trick in VAEs that allow backpropagation through the stochastic sampling procedure. \n",
        "3. Decoder - the decoder takes samples from the latent code and reconstructs to the original data. At inference time, we sample from a standard gaussian and allow the decoder to produce data from this random sample.\n",
        "4. Loss functions - For VAEs, we minimize the variational lower bound which can be separated to two main objectives; Reconstruction loss + KL divergence loss \n",
        "\n",
        "- The reconstruction loss is the loss incurred by the encoder in an attempt to reconstruct the original data whereas KL divergence is a measure of distance between the latent distribution and the prior distribution. Minimizing this objective is an important way to match the latent distribution with the prior distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sziy523DyJMR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "03c7f02a-6868-40ca-cadf-612230b95b6c"
      },
      "source": [
        "def encoder_model(num_chars, embedding_dim, max_seq_len, latent_dim, n_units):\n",
        "\n",
        "  '''\n",
        "  Encoder \n",
        "\n",
        "  Inputs\n",
        "    num_chars (int)      : Number of unique characters in dataset\n",
        "    embedding_dim (int)  : Embedding dimension\n",
        "    max_seq_len (int)    : max sequence length\n",
        "    latent_dim (int)     : latent dimension\n",
        "    n_rnn_units (int)    : number of rnn units\n",
        "\n",
        "  Outputs\n",
        "    (Keras Model Object) : takes data inputs and returns parameters of learned latent distribution \n",
        "  '''\n",
        "\n",
        "  inputs = Input(shape = (max_seq_len, ))\n",
        "  embedding = Embedding(num_chars, embedding_dim, input_length=max_seq_len, mask_zero=True)(inputs)\n",
        "  x = Bidirectional(LSTM(n_units))(embedding)\n",
        "  x = Dense(latent_dim*2)(x)\n",
        "  mu = Dense(latent_dim)(x)\n",
        "  sigma = Dense(latent_dim)(x)\n",
        "  model = tf.keras.Model(inputs, outputs = [mu, sigma])\n",
        "  return model\n",
        "\n",
        "plot_model(encoder_model(num_chars, embedding_dim, max_seq_len, latent_dim, n_units), dpi=70)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAUmCnNhCEAO"
      },
      "source": [
        "reparameterization \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "$$z = \\mu + e^{0.5\\sigma} * epsilon $$\n",
        "$epsilon \\sim \\mathcal{N}(0,1)\\$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWoiaAYmyJDi"
      },
      "source": [
        "def reparameterization(inputs):\n",
        "\n",
        "  \n",
        "  \"\"\"\n",
        "  Reparameterization function--> takes mean and sigma and reparameterize with samples\n",
        "   drawn from a standard normal distribution with mean 0 and standard deviation 1. \n",
        "\n",
        "  Inputs:\n",
        "   (mu, sigma): mean and standard deviation \n",
        "\n",
        "  Output:\n",
        "    z        : latent code \n",
        "\n",
        "   \"\"\"\n",
        "  mu, sigma = inputs\n",
        "  batch_ = tf.shape(mu)[0]\n",
        "  dim = tf.shape(mu)[1]\n",
        "  eps = random_normal((batch_, dim))\n",
        "  \n",
        "  return mu + tf.exp(0.5*sigma) * eps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLN6VvMFyJKL"
      },
      "source": [
        "def decoder_model(num_chars, max_seq_len, latent_dim, n_units):\n",
        "\n",
        "  \"\"\"\n",
        "  Decoder \n",
        "\n",
        "  Inputs\n",
        "    num_chars (int)      : Number of unique characters in dataset\n",
        "    max_seq_len (int)    : max sequence length\n",
        "    latent_dim (int)     : latent dimension\n",
        "    n_gru_units (int)    : number of gru units\n",
        "\n",
        "  Outputs\n",
        "    (Keras Model Object) : takes latent vectors as inputs and returns a \n",
        "                           softmax distribution over character set \n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  inputs = Input(shape = (latent_dim))\n",
        "  x = RepeatVector(max_seq_len)(inputs)\n",
        "  lstm_out = LSTM(n_units, return_sequences=True)(x)\n",
        "  output = Dense(num_chars, activation='softmax')(lstm_out)\n",
        "\n",
        "  model = Model(inputs, output)\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eII-wEfmWmpt"
      },
      "source": [
        "def sample_prior(batch_size, latent_dim):\n",
        "\n",
        "  \"\"\"\n",
        "  Sample prior       :  Sample for random normal distribution\n",
        "  Inputs:\n",
        "    batch_size (int) : number of samples to generate\n",
        "    latent_dim (int) : latent dimension\n",
        "\n",
        "  Outputs\n",
        "    samples from normal distribution (size = (batch_size, latent_dim))\n",
        "  \"\"\"\n",
        "\n",
        "  return random_normal((batch_size, latent_dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvFTD7kG9dTI"
      },
      "source": [
        "def kl_divergence_loss(inputs, outputs, mu, sigma):\n",
        "  \n",
        "  \"\"\" \n",
        "  Computes the Kullback-Leibler Divergence (KLD) loss\n",
        "  Inputs\n",
        "    inputs:  batch from the dataset\n",
        "    outputs: Output from the sample_z function/ layer\n",
        "    mu:      mean\n",
        "    sigma:   standard deviation\n",
        "\n",
        "  Outputs:\n",
        "    KL Divergence loss\n",
        "  # \"\"\"\n",
        "\n",
        "  rate = 0.5\n",
        "  kl_loss = 1 + sigma - tf.square(mu) - tf.math.exp(sigma)\n",
        "  kl_loss = -rate * tf.reduce_mean(kl_loss)\n",
        "\n",
        "  return kl_loss "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttPHwNP0V35c"
      },
      "source": [
        "def vae_model(encoder, decoder, max_seq_len):\n",
        "\n",
        "  \n",
        "  \"\"\"\n",
        "  Biulds a complete VAE model\n",
        "\n",
        "  Inputs\n",
        "    encoder     : the encoder model\n",
        "    decoder     : the decoder model\n",
        "    max_seq_len : length of sequence batch\n",
        "\n",
        "  Output:\n",
        "    the complete VAE model\n",
        "  \"\"\"\n",
        "\n",
        "  # set the inputs\n",
        "  input_x = tf.keras.layers.Input(shape=(max_seq_len, ))\n",
        "\n",
        "  # get mu, sigma, and z from the encoder output\n",
        "  mu, sigma = encoder(input_x)\n",
        "  \n",
        "  z = Lambda(reparameterization)(([mu, sigma]))\n",
        "  # get reconstructed output from the decoder\n",
        "  reconstructed = decoder(z)\n",
        "\n",
        "  # define the inputs and outputs of the VAE\n",
        "  model = tf.keras.Model(inputs=input_x, outputs=reconstructed)\n",
        "\n",
        "  # add the KL loss\n",
        "  loss = kl_divergence_loss(input_x, z, mu, sigma)\n",
        "  model.add_loss(loss)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTI6M_GTgcTN"
      },
      "source": [
        "We'll use the Adam optimizer and the sparse categorical cross entropy loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8jnxfBIW-VX"
      },
      "source": [
        "# Define our loss functions and optimizers\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "loss_metric = tf.keras.metrics.Mean()\n",
        "spce_loss = tf.keras.losses.SparseCategoricalCrossentropy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cli0o9ODheqA"
      },
      "source": [
        "# Initialize vae model\n",
        "def init_models(num_chars, embedding_dim, max_seq_len, latent_dim, n_units):\n",
        "  \"\"\" Model initializations here \"\"\"\n",
        "\n",
        "  encoder = encoder_model(num_chars, embedding_dim, max_seq_len, latent_dim, n_units)\n",
        "  decoder = decoder_model(num_chars, max_seq_len, latent_dim, n_units)\n",
        "  vae = vae_model(encoder, decoder, max_seq_len)\n",
        "  \n",
        "  return encoder, decoder, vae\n",
        "\n",
        "encoder, decoder, vae = init_models(num_chars, embedding_dim, max_seq_len, latent_dim, n_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4XDVewqcdg9",
        "outputId": "5061f656-dedc-4855-b592-d5afac9b20f8"
      },
      "source": [
        "# Training loop. \n",
        "\n",
        "epochs = 150 # Set the number of training epochs\n",
        "\n",
        "# prior = sample_prior(1, latent_dim)\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  # iterate over the batches of the dataset.\n",
        "  for step, batch in enumerate(train_dataset):\n",
        "    with tf.GradientTape() as tape:\n",
        "      \n",
        "      # feed a batch to the VAE model\n",
        "      reconstructed = vae(batch) # Get a batch of the training examples and feed to the vae model\n",
        "\n",
        "      loss = spce_loss(batch, reconstructed)  # compute the reconstruction loss between data and reconstruction\n",
        "\n",
        "      loss += sum(vae.losses)   # add the KL Divergence loss to reconstruction\n",
        "\n",
        "    grads = tape.gradient(loss, vae.trainable_weights)  # get the gradients with respect to the weights\n",
        "    optimizer.apply_gradients(zip(grads, vae.trainable_weights)) # Update the weights with gradients\n",
        "\n",
        "    loss_metric(loss) # compute the mean of losses\n",
        "    losses.append(loss_metric.result().numpy())\n",
        "    # # Show outputs at every 50 steps\n",
        "    if step % 50 == 0:\n",
        "      print('Epoch: %s step: %s average loss = %s ' % (epoch, step, loss_metric.result().numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 step: 0 average loss = 3.5142984 \n",
            "Epoch: 0 step: 50 average loss = 2.234938 \n",
            "Epoch: 1 step: 0 average loss = 2.1737137 \n",
            "Epoch: 1 step: 50 average loss = 1.9770994 \n",
            "Epoch: 2 step: 0 average loss = 1.933821 \n",
            "Epoch: 2 step: 50 average loss = 1.8217098 \n",
            "Epoch: 3 step: 0 average loss = 1.8022401 \n",
            "Epoch: 3 step: 50 average loss = 1.737471 \n",
            "Epoch: 4 step: 0 average loss = 1.7224969 \n",
            "Epoch: 4 step: 50 average loss = 1.6784 \n",
            "Epoch: 5 step: 0 average loss = 1.6666652 \n",
            "Epoch: 5 step: 50 average loss = 1.6303576 \n",
            "Epoch: 6 step: 0 average loss = 1.621781 \n",
            "Epoch: 6 step: 50 average loss = 1.5941923 \n",
            "Epoch: 7 step: 0 average loss = 1.5875555 \n",
            "Epoch: 7 step: 50 average loss = 1.5649297 \n",
            "Epoch: 8 step: 0 average loss = 1.559903 \n",
            "Epoch: 8 step: 50 average loss = 1.5433537 \n",
            "Epoch: 9 step: 0 average loss = 1.5390197 \n",
            "Epoch: 9 step: 50 average loss = 1.5226864 \n",
            "Epoch: 10 step: 0 average loss = 1.5184797 \n",
            "Epoch: 10 step: 50 average loss = 1.5165317 \n",
            "Epoch: 11 step: 0 average loss = 1.514083 \n",
            "Epoch: 11 step: 50 average loss = 1.5027483 \n",
            "Epoch: 12 step: 0 average loss = 1.4998417 \n",
            "Epoch: 12 step: 50 average loss = 1.4875394 \n",
            "Epoch: 13 step: 0 average loss = 1.4849648 \n",
            "Epoch: 13 step: 50 average loss = 1.4754233 \n",
            "Epoch: 14 step: 0 average loss = 1.4725232 \n",
            "Epoch: 14 step: 50 average loss = 1.4645703 \n",
            "Epoch: 15 step: 0 average loss = 1.4623482 \n",
            "Epoch: 15 step: 50 average loss = 1.4536752 \n",
            "Epoch: 16 step: 0 average loss = 1.4517169 \n",
            "Epoch: 16 step: 50 average loss = 1.4437991 \n",
            "Epoch: 17 step: 0 average loss = 1.4415729 \n",
            "Epoch: 17 step: 50 average loss = 1.434491 \n",
            "Epoch: 18 step: 0 average loss = 1.4324598 \n",
            "Epoch: 18 step: 50 average loss = 1.4249191 \n",
            "Epoch: 19 step: 0 average loss = 1.4232475 \n",
            "Epoch: 19 step: 50 average loss = 1.4162774 \n",
            "Epoch: 20 step: 0 average loss = 1.414704 \n",
            "Epoch: 20 step: 50 average loss = 1.4091803 \n",
            "Epoch: 21 step: 0 average loss = 1.4072201 \n",
            "Epoch: 21 step: 50 average loss = 1.4014738 \n",
            "Epoch: 22 step: 0 average loss = 1.3995883 \n",
            "Epoch: 22 step: 50 average loss = 1.3944175 \n",
            "Epoch: 23 step: 0 average loss = 1.392605 \n",
            "Epoch: 23 step: 50 average loss = 1.3876243 \n",
            "Epoch: 24 step: 0 average loss = 1.3861954 \n",
            "Epoch: 24 step: 50 average loss = 1.3818325 \n",
            "Epoch: 25 step: 0 average loss = 1.380339 \n",
            "Epoch: 25 step: 50 average loss = 1.3761367 \n",
            "Epoch: 26 step: 0 average loss = 1.374897 \n",
            "Epoch: 26 step: 50 average loss = 1.3708436 \n",
            "Epoch: 27 step: 0 average loss = 1.369455 \n",
            "Epoch: 27 step: 50 average loss = 1.366022 \n",
            "Epoch: 28 step: 0 average loss = 1.364741 \n",
            "Epoch: 28 step: 50 average loss = 1.3605801 \n",
            "Epoch: 29 step: 0 average loss = 1.3598236 \n",
            "Epoch: 29 step: 50 average loss = 1.3565996 \n",
            "Epoch: 30 step: 0 average loss = 1.3555653 \n",
            "Epoch: 30 step: 50 average loss = 1.3521274 \n",
            "Epoch: 31 step: 0 average loss = 1.3511407 \n",
            "Epoch: 31 step: 50 average loss = 1.3478526 \n",
            "Epoch: 32 step: 0 average loss = 1.3472526 \n",
            "Epoch: 32 step: 50 average loss = 1.3438603 \n",
            "Epoch: 33 step: 0 average loss = 1.3430461 \n",
            "Epoch: 33 step: 50 average loss = 1.3400503 \n",
            "Epoch: 34 step: 0 average loss = 1.3391452 \n",
            "Epoch: 34 step: 50 average loss = 1.3360978 \n",
            "Epoch: 35 step: 0 average loss = 1.3352271 \n",
            "Epoch: 35 step: 50 average loss = 1.3324642 \n",
            "Epoch: 36 step: 0 average loss = 1.3318273 \n",
            "Epoch: 36 step: 50 average loss = 1.3292656 \n",
            "Epoch: 37 step: 0 average loss = 1.3285778 \n",
            "Epoch: 37 step: 50 average loss = 1.3256717 \n",
            "Epoch: 38 step: 0 average loss = 1.3250723 \n",
            "Epoch: 38 step: 50 average loss = 1.3224435 \n",
            "Epoch: 39 step: 0 average loss = 1.3216177 \n",
            "Epoch: 39 step: 50 average loss = 1.3194419 \n",
            "Epoch: 40 step: 0 average loss = 1.3187691 \n",
            "Epoch: 40 step: 50 average loss = 1.3164979 \n",
            "Epoch: 41 step: 0 average loss = 1.315981 \n",
            "Epoch: 41 step: 50 average loss = 1.3134277 \n",
            "Epoch: 42 step: 0 average loss = 1.3128599 \n",
            "Epoch: 42 step: 50 average loss = 1.3107789 \n",
            "Epoch: 43 step: 0 average loss = 1.309956 \n",
            "Epoch: 43 step: 50 average loss = 1.3077157 \n",
            "Epoch: 44 step: 0 average loss = 1.3070858 \n",
            "Epoch: 44 step: 50 average loss = 1.3049167 \n",
            "Epoch: 45 step: 0 average loss = 1.3042707 \n",
            "Epoch: 45 step: 50 average loss = 1.3024755 \n",
            "Epoch: 46 step: 0 average loss = 1.3019087 \n",
            "Epoch: 46 step: 50 average loss = 1.2999324 \n",
            "Epoch: 47 step: 0 average loss = 1.2993708 \n",
            "Epoch: 47 step: 50 average loss = 1.2973181 \n",
            "Epoch: 48 step: 0 average loss = 1.2968628 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32cdzbxLpTaE"
      },
      "source": [
        "generate_random_smiles(decoder, 5, latent_dim, decoding_strategy='temp', temperature=0.1) # Lets generate some random samples with the trained decoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFuhUOBTBJ56"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}